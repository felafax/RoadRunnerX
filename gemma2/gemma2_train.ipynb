{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5OeTiryEcoX"
   },
   "source": [
    "# Fine-tuning Gemma2 2B model on Roadrunner with JAX, Flax.\n",
    "\n",
    "We have adopted the Gemma2 notebook from Google Deepmind to use HuggingFace's libraries and and simplified the steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5m81VQOqEcoX"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade kagglehub -q\n",
    "!pip install ipywidgets -q\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cpu -q\n",
    "!pip install git+https://github.com/felafax/gemma.git -q\n",
    "!pip install qax -q\n",
    "!pip install jax-lorax -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HUB_CACHE'] = '/mnt/persistent-disk/hf/'\n",
    "os.environ['HF_HOME'] = '/mnt/persistent-disk/hf/'\n",
    "!export HF_HUB_CACHE=\"/mnt/persistent-disk/hf/\"\n",
    "!export HF_HOME=\"/mnt/persistent-disk/hf/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "yWaP_LPoEcoY"
   },
   "outputs": [],
   "source": [
    "# @title Python imports\n",
    "\n",
    "import enum\n",
    "import re\n",
    "import string\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# We import JAX and some related packages.\n",
    "import chex\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax\n",
    "import flax.linen as nn\n",
    "from flax.training import train_state\n",
    "from flax.traverse_util import flatten_dict\n",
    "from flax.core.meta import unbox\n",
    "\n",
    "import optax\n",
    "import functools\n",
    "from functools import partial\n",
    "\n",
    "# Model partitioning related imports\n",
    "from jax.sharding import Mesh, NamedSharding\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from jax.lax import with_sharding_constraint\n",
    "from jax.experimental import mesh_utils\n",
    "\n",
    "\n",
    "# For LoRA\n",
    "import lorax\n",
    "\n",
    "# We will use HuggingFace's dataset, tokenizer, and model classes.\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer, default_data_collator\n",
    "from datasets import Dataset, load_dataset, concatenate_datasets\n",
    "import torch\n",
    "\n",
    "# Finally, we import Gemma.\n",
    "from gemma import params as params_lib\n",
    "from gemma import sampler as sampler_lib\n",
    "from gemma import transformer as transformer_lib\n",
    "import sentencepiece as spm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "INPUT: Please provide your HUGGINGFACE_USERNAME:  felarof01\n",
      "INPUT: Please provide your HUGGINGFACE_TOKEN:  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\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace username and token to use when downloading.\n",
    "MODEL_NAME=\"felafax/gemma-2-2b-it-Flax\"\n",
    "HUGGINGFACE_USERNAME = input(\"INPUT: Please provide your HUGGINGFACE_USERNAME: \")\n",
    "HUGGINGFACE_TOKEN = input(\"INPUT: Please provide your HUGGINGFACE_TOKEN: \")\n",
    "\n",
    "model_name=MODEL_NAME\n",
    "hugging_face_token=HUGGINGFACE_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "ckpt_path = snapshot_download(repo_id=MODEL_NAME, token=HUGGINGFACE_TOKEN)\n",
    "vocab_path = os.path.join(ckpt_path, 'tokenizer.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VsT2o6JEcoZ"
   },
   "source": [
    "## Fine tuning the Gemma model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import flax\n",
    "from flax.traverse_util import flatten_dict\n",
    "\n",
    "def print_params(params):\n",
    "    flat_params = flatten_dict(params)    \n",
    "    for key, value in flat_params.items():\n",
    "        name = \"/\".join(str(x) for x in key)\n",
    "        print(f\"Name: {name}\")\n",
    "        # print(f\"Shape: {value.shape}\")\n",
    "        # print(f\"dtype: {value.dtype}\")\n",
    "        # print(f\"Value: {value}\")\n",
    "        if isinstance(value, flax.core.meta.Partitioned):\n",
    "            array = unbox(value)\n",
    "        else:\n",
    "            array = value\n",
    "        print(jax.debug.visualize_array_sharding(array))\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: prepare the dataset\n",
    "\n",
    "For this project, we're utilizing the refined **Alpaca dataset**, curated by yahma. This dataset is a carefully filtered selection of 52,000 entries from the original Alpaca collection. Feel free to substitute this section with your own data preparation code if you prefer.\n",
    "\n",
    "It's crucial to include the EOS_TOKEN (End of Sequence Token) in your tokenized output. Failing to do so may result in endless generation loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(*, tokenizer, batch_size=1, max_length=32, max_examples=32):\n",
    "    # Define Alpaca prompt template\n",
    "    alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "    \n",
    "    ### Instruction: {}\n",
    "    \n",
    "    ### Input: {}\n",
    "    \n",
    "    ### Response: {}\"\"\"\n",
    "    \n",
    "    EOS_TOKEN = tokenizer.eos_token\n",
    "    \n",
    "    # Define formatting function.\n",
    "    def _format_prompts(examples):\n",
    "        instructions = examples[\"instruction\"]\n",
    "        inputs = examples[\"input\"]\n",
    "        outputs = examples[\"output\"]\n",
    "        texts = []\n",
    "        for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "            text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "            texts.append(text)\n",
    "        return {\"text\": texts}\n",
    "\n",
    "    def _tokenize(examples):\n",
    "        tokenized = tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=max_length+1)\n",
    "        tokenized['input_ids'] = [input_id[:-1] for input_id in tokenized['input_ids']]\n",
    "        tokenized['target_mask'] = [input_id[:-1] for input_id in tokenized['attention_mask']]\n",
    "        return {\n",
    "            'input_tokens': tokenized['input_ids'],\n",
    "            'target_mask': tokenized['target_mask']\n",
    "        }\n",
    "\n",
    "    def _custom_collate_fn(batch):\n",
    "        \"\"\"Applies default_collate_fn from transformers and converts to JAX NumPy arrays.\"\"\"\n",
    "        batch = default_data_collator(batch)\n",
    "        jax_batch = {}\n",
    "        for key, value in batch.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                jax_batch[key] = jnp.array(value.numpy())\n",
    "            else:\n",
    "                jax_batch[key] = value\n",
    "        \n",
    "        return jax_batch\n",
    "\n",
    "    # Load and preprocess the dataset.\n",
    "    dataset = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\")\n",
    "    if max_examples:\n",
    "        dataset = dataset.select(range(max_examples))\n",
    "    dataset = dataset.map(_format_prompts, batched=True)\n",
    "\n",
    "    # Create train and test dataset.\n",
    "    ds = dataset.train_test_split(test_size=0.15)\n",
    "    ds['train'] = ds['train'].map(_tokenize, batched=True, remove_columns=dataset.column_names)\n",
    "    ds['test'] = ds['test'].map(_tokenize, batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        ds['train'],\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=_custom_collate_fn\n",
    "    )\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        ds['test'],\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=_custom_collate_fn\n",
    "    )\n",
    "\n",
    "    return train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6a0a48b85f4c97b3a144c9af0438a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72d95d0a49442bcb5461101ce88d1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n",
      "(1, 32)\n",
      "\n",
      "(1, 32)\n"
     ]
    }
   ],
   "source": [
    "# # # Test Dataset\n",
    "train_dataloader, _ = get_dataset(tokenizer=tokenizer)\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i>10:\n",
    "        break\n",
    "    input_ids, attention_mask = (\n",
    "        batch[\"input_tokens\"],\n",
    "        batch[\"target_mask\"],\n",
    "        \n",
    "    )\n",
    "    print(input_ids.shape)\n",
    "    print()\n",
    "    print(attention_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "cellView": "form",
    "id": "iEcV0XEEEcoZ"
   },
   "outputs": [],
   "source": [
    "def forward_and_loss_fn(params,\n",
    "                        *,\n",
    "                        state,\n",
    "                        input_tokens: jax.Array,            # Shape [B, L]\n",
    "                        input_mask: jax.Array,              # Shape [B, L]\n",
    "                        positions: jax.Array,               # Shape [B, L]\n",
    "                        attention_mask: jax.Array,          # [B, L, L]\n",
    "                        ) -> jax.Array:\n",
    "  \"\"\"Forward pass and loss function.\n",
    "\n",
    "  Args:\n",
    "    params: model's input parameters.\n",
    "    model: gemma transformer model to call.\n",
    "    input_tokens: input tokens sequence, shape [B, L].\n",
    "    input_mask: tokens to ignore when computing the loss, shape [B, L].\n",
    "    positions: relative position of each token, shape [B, L].\n",
    "    attention_mask: input attention mask, shape [B, L].\n",
    "\n",
    "  Returns:\n",
    "    Softmax cross-entropy loss for the next-token prediction task.\n",
    "  \"\"\"\n",
    "\n",
    "  # Forward pass on the input data.\n",
    "  # No attention cache is needed here.\n",
    "  logits, _ = state.apply_fn(\n",
    "        params,\n",
    "        input_tokens,\n",
    "        positions,\n",
    "        None,              # Attention cache is None.\n",
    "        attention_mask,\n",
    "    )\n",
    "\n",
    "  # Exclude the last step as it does not appear in the targets.\n",
    "  logits = logits[:, :-1]\n",
    "\n",
    "  # Similarly, the first token cannot be predicteds.\n",
    "  target_tokens = input_tokens[:, 1:]\n",
    "  target_mask = input_mask[:, 1:]\n",
    "\n",
    "  # Convert the target labels into one-hot encoded vectors.\n",
    "  one_hot = jax.nn.one_hot(target_tokens, logits.shape[-1])\n",
    "\n",
    "  # Don't update on unwanted tokens.\n",
    "  one_hot = one_hot * target_mask.astype(one_hot.dtype)[..., None]\n",
    "\n",
    "  # Normalisation factor.\n",
    "  norm_factor = 1 / (jnp.sum(target_mask) + 1e-8)\n",
    "\n",
    "  # Return the nll loss.\n",
    "  return -jnp.sum(jax.nn.log_softmax(logits) * one_hot) * norm_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y83DimpjEcoZ"
   },
   "source": [
    "The Gemma transformer requires an attention mask and position vector alongside each input. We can conveniently generate these using the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "cellView": "form",
    "id": "cbWfdHf0EcoZ"
   },
   "outputs": [],
   "source": [
    "def get_attention_mask_and_positions(example: jax.Array,\n",
    "                                     pad_id : int,\n",
    "                                     )-> tuple[jax.Array, jax.Array]:\n",
    "  \"\"\"Builds the position and attention mask vectors from the given tokens.\"\"\"\n",
    "  pad_mask = example != pad_id\n",
    "  current_token_position = transformer_lib.build_positions_from_mask(pad_mask)\n",
    "  attention_mask = transformer_lib.make_causal_attn_mask(pad_mask)\n",
    "  return current_token_position, attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbxYMMWLEcoZ"
   },
   "source": [
    "We can now build the train_step function which performs the backward pass and updates the model's parameters accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "cellView": "form",
    "id": "cPSfp7ZUEcoZ"
   },
   "outputs": [],
   "source": [
    "def train_step(state,\n",
    "               params,\n",
    "               optimizer: optax.GradientTransformation,\n",
    "               opt_state: optax.OptState,\n",
    "               pad_id: int,\n",
    "               batch):\n",
    "  \"\"\"Train step.\n",
    "\n",
    "  Args:\n",
    "    model: gemma transformer model.\n",
    "    params: model's input parameters.\n",
    "    optimizer: optax optimizer to use.\n",
    "    opt_state: input optimizer's state.\n",
    "    pad_id: id of the pad token.\n",
    "    batch: input batch.\n",
    "\n",
    "  Returns:\n",
    "    Training loss, updated parameters, updated optimizer state.\n",
    "  \"\"\"\n",
    "  # Build the position and attention mask vectors.\n",
    "  positions, attention_mask = get_attention_mask_and_positions(batch['input_tokens'], pad_id)\n",
    "\n",
    "  # Forward and backward passes\n",
    "  train_loss, grads = jax.value_and_grad(forward_and_loss_fn)(params,\n",
    "                                                             state=state,\n",
    "                                                             input_tokens=batch['input_tokens'],\n",
    "                                                             input_mask=batch['target_mask'],\n",
    "                                                             positions=positions,\n",
    "                                                             attention_mask=attention_mask)\n",
    "  # Update the parameters\n",
    "  # updates, opt_state = optimizer.update(grads, opt_state)\n",
    "  # params = optax.apply_updates(params, updates)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "\n",
    "  return train_loss, params, opt_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2QXp116EcoZ"
   },
   "source": [
    "Similarly, we build a `validation_step` function without backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6g6LFWJbEcoa"
   },
   "source": [
    "And now the training loop itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
       " TpuDevice(id=1, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
       " TpuDevice(id=2, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
       " TpuDevice(id=3, process_index=0, coords=(1,1,0), core_on_chip=0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the device mesh\n",
    "devices = jax.devices()\n",
    "device_mesh = mesh_utils.create_device_mesh((1, 4))\n",
    "mesh = Mesh(devices=device_mesh, axis_names=('data', 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters.\n",
    "params = {\"params\": params_lib.load_and_format_params(os.path.join(ckpt_path, 'gemma2-2b-it'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model config.\n",
    "config = transformer_lib.TransformerConfig.gemma2_2b(cache_size=30)\n",
    "model = transformer_lib.Transformer(config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    token=HUGGINGFACE_TOKEN\n",
    ")\n",
    "optimizer = optax.sgd(training_cfg.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_fn(params, model, optimizer):\n",
    "    state = train_state.TrainState.create(\n",
    "        apply_fn=model.apply,\n",
    "        params=params['params'],\n",
    "        tx=optimizer)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def init_fn(params, model, optimizer, mesh):\n",
    "#     def shard_param(param):\n",
    "#         if len(param.shape) == 1:\n",
    "#             return NamedSharding(mesh, P('model'))\n",
    "#         elif len(param.shape) == 2:\n",
    "#             return NamedSharding(mesh, P('data', 'model'))\n",
    "#         else:\n",
    "#             return NamedSharding(mesh, P(None))\n",
    "\n",
    "#     sharded_params = jax.tree_util.tree_map(shard_param, params['params'])\n",
    "    \n",
    "#     state = train_state.TrainState.create(\n",
    "#         apply_fn=model.apply,\n",
    "#         params=sharded_params,\n",
    "#         tx=optimizer)\n",
    "#     return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_variables = jax.eval_shape(\n",
    "    functools.partial(\n",
    "        init_fn,\n",
    "        params=params,\n",
    "        model=model, \n",
    "        optimizer=optimizer,\n",
    "        # mesh=mesh\n",
    "    ),\n",
    ")\n",
    "abstract_sharded_state = nn.get_sharding(abstract_variables, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_abstract_params(params):\n",
    "#     return jax.tree_map(lambda x: jax.ShapeDtypeStruct(x.shape, x.dtype), params)\n",
    "\n",
    "# abstract_params = get_abstract_params(params)\n",
    "\n",
    "# abstract_variables = jax.eval_shape(\n",
    "#     functools.partial(\n",
    "#         init_fn,\n",
    "#         sharded_params={'params': abstract_params},\n",
    "#         model=model, \n",
    "#         optimizer=optimizer,\n",
    "#     ),\n",
    "# )\n",
    "# abstract_sharded_state = nn.get_sharding(abstract_variables, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard_params_pytree(params, mesh):\n",
    "    def shard_param(param):\n",
    "        # Define sharding based on param shape\n",
    "        if len(param.shape) == 1:\n",
    "            # For 1D tensors (e.g., biases), shard across 'model' dimension\n",
    "            return NamedSharding(mesh, P('model'))\n",
    "        elif len(param.shape) == 2:\n",
    "            # For 2D tensors (e.g., weight matrices), shard across both dimensions\n",
    "            return NamedSharding(mesh, P('data', 'model'))\n",
    "        else:\n",
    "            # For higher-dimensional tensors, you might need a more complex strategy\n",
    "            return NamedSharding(mesh, P(None))  # Replicate by default\n",
    "\n",
    "    return jax.tree_util.tree_map(shard_param, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = shard_params_pytree(params, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_fn_jitted = jax.jit(\n",
    "    init_fn, \n",
    "    static_argnums=(1, 2),\n",
    "    in_shardings=(\n",
    "        jax.tree_util.tree_map(lambda x: x, params),  # Use the shardings directly\n",
    "        None,\n",
    "        None\n",
    "    ),\n",
    "    out_shardings=abstract_sharded_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret value of type <class 'jaxlib.xla_extension.NamedSharding'> as an abstract array; it does not have a dtype attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mesh:\n\u001b[0;32m----> 2\u001b[0m     sharded_state \u001b[38;5;241m=\u001b[39m \u001b[43minit_fn_jitted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/jax/_src/api_util.py:576\u001b[0m, in \u001b[0;36m_shaped_abstractify_slow\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    574\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(x\u001b[38;5;241m.\u001b[39mdtype, allow_extended_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 576\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot interpret value of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as an abstract array; it \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not have a dtype attribute\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m core\u001b[38;5;241m.\u001b[39mShapedArray(np\u001b[38;5;241m.\u001b[39mshape(x), dtype, weak_type\u001b[38;5;241m=\u001b[39mweak_type)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret value of type <class 'jaxlib.xla_extension.NamedSharding'> as an abstract array; it does not have a dtype attribute"
     ]
    }
   ],
   "source": [
    "with mesh:\n",
    "    sharded_state = init_fn_jitted(params, model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = jax.device_put(sample_batch, NamedSharding(mesh, PartitionSpec('data', 'model')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_train_step = jax.jit(train_step, static_argnames=['model', 'optimizer'])\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, params, opt_state = train_step(model=model,\n",
    "                                            params=params,\n",
    "                                            optimizer=optimizer,\n",
    "                                            opt_state=opt_state,\n",
    "                                            pad_id=tokenizer.pad_token_id,\n",
    "                                            example=train_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cfg = TrainingConfig(learning_rate=1e-4,\n",
    "                              num_epochs=1,\n",
    "                              eval_every_n=20,\n",
    "                              batch_size=1,\n",
    "                              max_steps=10)\n",
    "\n",
    "params = train_loop(model=model_2b,\n",
    "                    params={'params': params['transformer']},\n",
    "                    train_dataloader=train_dataloader,\n",
    "                    tokenizer=tokenizer,\n",
    "                    training_cfg=training_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cellView": "form",
    "id": "xT4bAqNLEcoa"
   },
   "outputs": [],
   "source": [
    "@chex.dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "  learning_rate: float\n",
    "  num_epochs: int\n",
    "  eval_every_n: int\n",
    "  batch_size: int\n",
    "  max_steps: int | None = None\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_loop(\n",
    "    model: transformer_lib.Transformer,\n",
    "    params,\n",
    "    train_dataloader,\n",
    "    tokenizer,\n",
    "    training_cfg: TrainingConfig):\n",
    "\n",
    "\n",
    "  compiled_train_step = jax.jit(train_step, static_argnames=['model', 'optimizer'])\n",
    "  optimizer = optax.sgd(training_cfg.learning_rate)\n",
    "  opt_state = optimizer.init(params)\n",
    "\n",
    "  n_steps = 0\n",
    "  avg_loss=0\n",
    "\n",
    "  for i, train_example in enumerate(train_dataloader):\n",
    "    train_loss, params, opt_state = train_step(model=model,\n",
    "                                                        params=params,\n",
    "                                                        optimizer=optimizer,\n",
    "                                                        opt_state=opt_state,\n",
    "                                                        pad_id=tokenizer.pad_token_id,\n",
    "                                                        example=train_example)\n",
    "    n_steps += 1\n",
    "    avg_loss += train_loss\n",
    "    print(f\"train_loss {train_loss}\")\n",
    "    if training_cfg.max_steps is not None and n_steps > training_cfg.max_steps:\n",
    "      break\n",
    "  return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muwkf_ZgEcoa"
   },
   "source": [
    "We can fine-tune our model on a limited number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cellView": "form",
    "id": "7SL2VAmVEcoa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_2b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m training_cfg \u001b[38;5;241m=\u001b[39m TrainingConfig(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m      2\u001b[0m                               num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m                               eval_every_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      4\u001b[0m                               batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m                               max_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m params \u001b[38;5;241m=\u001b[39m train_loop(model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_2b\u001b[49m,\n\u001b[1;32m      8\u001b[0m                     params\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer\u001b[39m\u001b[38;5;124m'\u001b[39m]},\n\u001b[1;32m      9\u001b[0m                     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_dataloader,\n\u001b[1;32m     10\u001b[0m                     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     11\u001b[0m                     training_cfg\u001b[38;5;241m=\u001b[39mtraining_cfg)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_2b' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
